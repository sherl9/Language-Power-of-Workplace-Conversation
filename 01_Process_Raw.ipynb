{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e388428c-66fa-4bbb-a7f1-8112b8d72b08",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60d14bf-3ced-4cc6-86f7-50b5e240348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser as cp\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d16fc9c-5048-4d64-b175-9d56b8fec193",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a12b1367-c996-4158-9bbf-79d6bb3db6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = cp.RawConfigParser()\n",
    "config.read(r'config.txt')\n",
    "\n",
    "# @slack_dir: directory of unziped raw slack data\n",
    "# @proc_file: file where you want to store the combined&processed dataframe\n",
    "slack_dir = config.get('main', 'slack_dir')\n",
    "proc_file = config.get('main', 'proc_file')\n",
    "slack_text_file = config.get('analysis', 'slack_text_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d7ae38-9f81-4fa1-b073-874009184700",
   "metadata": {},
   "source": [
    "# Read essential channel and member info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4acb0f-8880-44cd-acdd-70fe0de14dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @chann_json: json file that stores channel metadata\n",
    "# @user_json: json file that stores user metadata\n",
    "chann_json = os.path.join('data', slack_dir, 'channels.json')\n",
    "user_json  = os.path.join('data', slack_dir, 'users.json')\n",
    "\n",
    "df_chann = pd.read_json(chann_json)\n",
    "df_user = pd.read_json(user_json)\n",
    "\n",
    "# @chann_lst: list of channel names\n",
    "# @chann_member_dct: map of channels and corresponding member ids\n",
    "chann_lst = df_chann['name'].tolist()\n",
    "chann_member_dct = dict(zip(df_chann.name, df_chann.members))\n",
    "\n",
    "# @user_lst: list of human user ids (excluding bot users or app users)\n",
    "# @name_lst: list of human user first names\n",
    "user_lst = df_user.loc[(df_user['is_bot'] == False) & (df_user['is_app_user'] == False)]['id'].tolist()\n",
    "name_lst = df_user.loc[(df_user['is_bot'] == False) & (df_user['is_app_user'] == False)]['real_name'].tolist()\n",
    "\n",
    "# Generate a valid first name that will be used to replace \"@\" symbols in texts\n",
    "def get_first_name(name):\n",
    "    name_split_lst = name.split(' ')\n",
    "    first_name = name_split_lst[0]\n",
    "    title_lst = ['Mr', 'Mrs', 'Miss', 'Ms', 'Mx', 'Sir', 'Dr', 'Cllr', 'Lady', 'Lord']\n",
    "    for title in title_lst:\n",
    "        if title in first_name and len(name_split_lst) > 0:\n",
    "            first_name = name_split_lst[1]\n",
    "            break\n",
    "    return first_name\n",
    "\n",
    "name_lst = [get_first_name(name) for name in name_lst]\n",
    "\n",
    "# @user_name_dct: map of user ids and first names (for preprocessing)\n",
    "user_name_dct = dict(zip(user_lst, name_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f39470-b003-4c7d-b38a-60d7110e97b2",
   "metadata": {},
   "source": [
    "# Combine all messages into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe86b059-e131-40a0-a7d2-6fef3cf786d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine a single channel\n",
    "def merge_a_channel(channel):\n",
    "    cur_dir = os.path.join('data', slack_dir, channel)\n",
    "    file_lst = sorted(glob(cur_dir + '/*.json'))\n",
    "    df_lst = []\n",
    "    for file in file_lst:\n",
    "        cur_df = pd.read_json(file)\n",
    "        df_lst.append(cur_df)\n",
    "    chann_df = pd.concat(df_lst, ignore_index=True, join='outer')\n",
    "    chann_df.insert(0, 'channel', channel)\n",
    "    return chann_df\n",
    "\n",
    "# Combine all channels\n",
    "def merge_all_channels(chann_lst):\n",
    "    chann_df_lst = []\n",
    "    for channel in chann_lst:\n",
    "        chann_df = merge_a_channel(channel)\n",
    "        chann_df_lst.append(chann_df)\n",
    "    return pd.concat(chann_df_lst, ignore_index=True, join='outer')\n",
    "\n",
    "# @df_raw: the combined raw dataframe\n",
    "df_raw = merge_all_channels(chann_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a7f17a-df53-4b40-937a-735c0251afb8",
   "metadata": {},
   "source": [
    "# Preprocessing: first step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f1ee0f-4ee9-49eb-b682-4bdbff02d8d7",
   "metadata": {},
   "source": [
    "### Extract only useful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c02da72b-844a-463c-ace6-73e789d7681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @attr_lst: list of useful metadata attributes\n",
    "useful_attr_lst = [ \n",
    "    'type', \n",
    "    'subtype', \n",
    "    'ts', \n",
    "    'thread_ts',\n",
    "    'channel',\n",
    "    'user', \n",
    "    'text', \n",
    "    'reactions', \n",
    "    'replies',\n",
    "    'parent_user_id']\n",
    "df_processed = df_raw.filter(useful_attr_lst, axis=1)\n",
    "\n",
    "# Replace NaN values with None\n",
    "df_processed = df_processed.replace({np.nan: None})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0441e-4a31-4e0d-97da-ddcf029ad85b",
   "metadata": {},
   "source": [
    "### Extract only text messages\n",
    "\n",
    "Ignore \"XX has joined channel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b7c788ee-93cc-486f-a9a0-0f051392bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process 'type' and 'subtype'\n",
    "df_processed = df_processed.loc[\n",
    "    (df_processed['type']=='message') & \n",
    "    (df_processed['subtype'].isnull())]\n",
    "\n",
    "useless_attr_list = ['type', 'subtype']\n",
    "df_processed = df_processed.drop(columns=useless_attr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19b6b9-7ceb-4b12-a4ee-90c3ad5c0d43",
   "metadata": {},
   "source": [
    "### Transform UNIX timestamps to human-readable formats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c9537e6f-1e6c-4993-9127-17cddce4dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process 'ts'\n",
    "def get_date(ts):\n",
    "    return datetime.datetime.fromtimestamp(ts).date()\n",
    "\n",
    "# Create 'date'\n",
    "df_processed['date'] = df_processed['ts'].apply(get_date)\n",
    "\n",
    "# Create 'week' number\n",
    "min_date = df_processed['date'].min()\n",
    "\n",
    "def get_week(date):\n",
    "    delta = date - min_date\n",
    "    days = delta.days\n",
    "    return 1 + (days // 7)\n",
    "\n",
    "df_processed['week'] = df_processed['date'].apply(get_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec97de1-ab25-450f-8137-b34adeb7fda6",
   "metadata": {},
   "source": [
    "# Indentify interactions\n",
    "\n",
    "A user connects to (interacts with) another user by replying to them or mentioning them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a586ad-9ad5-4f09-ae7e-4d1b5e1cb08c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Identify channel members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "91b8eb49-68fd-4253-aa07-a2f17d531634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_members(channel):\n",
    "    member_lst = chann_member_dct[channel]\n",
    "    return member_lst\n",
    "\n",
    "df_processed['members'] = df_processed['channel'].apply(get_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89459f56-080d-49d2-b156-a41e9c42bdd6",
   "metadata": {},
   "source": [
    "### Identify direct mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cbb49dcc-8b80-4906-a2a6-f83d678d3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify '<@user_id>' in 'text'\n",
    "# Add 'mentions'\n",
    "def get_mentions(text):\n",
    "    regex = r'\\<@(.*?)\\>'\n",
    "    mentions = re.findall(regex, text)\n",
    "    mention_lst = list(set(mentions) & set(user_lst)) # must be a valid user \n",
    "    return mention_lst\n",
    "\n",
    "df_processed['mentions'] = df_processed['text'].apply(get_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e9228c-05c3-438c-ab77-78936f9a3b5f",
   "metadata": {},
   "source": [
    "### Identify explicit addressees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "58411745-f7d1-45e7-8431-ad9050f0bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit addressees = mentions + parent user\n",
    "def get_explicit_addressees(row):\n",
    "    if row['parent_user_id'] != None:\n",
    "        explicit_addressees = [row['parent_user_id']] + row['mentions']\n",
    "        explicit_addressees_set = set(explicit_addressees)\n",
    "        speaker = row['user']\n",
    "        if speaker in explicit_addressees_set:\n",
    "            explicit_addressees_set.remove(row['user'])\n",
    "        explicit_addressees_lst = list(explicit_addressees_set)\n",
    "        return explicit_addressees_lst\n",
    "    return row['mentions']\n",
    "\n",
    "df_processed['explicit_addressees'] = df_processed.apply(lambda row: get_explicit_addressees(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757a0a3-3f3c-4f22-be9b-70a47d5ea241",
   "metadata": {},
   "source": [
    "# Text cleaning\n",
    "\n",
    "* Remove extra spaces and newlines\n",
    "* Replace html escape charaters\n",
    "* Replace URLs with a placeholder (\\<url\\>)\n",
    "* Replace mentions (\\<@UID\\>) with valid user names\n",
    "* Remove extremely short messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ed8e5256-733f-428a-bac6-75f04716eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces and newlines\n",
    "def remove_spaces(text):\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "df_processed['text'] = df_processed['text'].apply(remove_spaces)\n",
    "\n",
    "# Replace html escape charaters (unescaping)\n",
    "unescape_dct = {'&lt;': '<',\n",
    "                '&gt;': '>',\n",
    "                '&quot;': '\"',\n",
    "                '&#39;':'\\'',\n",
    "                '&amp;': '&'}\n",
    "\n",
    "def replace_escapes(text):\n",
    "    for s in unescape_dct:\n",
    "        c = unescape_dct[s]\n",
    "        text = text.replace(s, c)\n",
    "    return text\n",
    "\n",
    "df_processed['text'] = df_processed['text'].apply(replace_escapes)\n",
    "\n",
    "# Replace URLs with a placeholder '<url>'\n",
    "def replace_urls(text):\n",
    "    regex1 = r'https?://\\S+'\n",
    "    regex2 = r'http?://\\S+'\n",
    "    text = re.sub(regex1, 'url>', text)\n",
    "    text = re.sub(regex2, 'url>', text)\n",
    "    return text\n",
    "\n",
    "df_processed['text'] = df_processed['text'].apply(replace_urls)\n",
    "\n",
    "# Replace mentions ('<@user_id>') in 'text' with valid user names\n",
    "def replace_mentions(text):\n",
    "    regex = r'\\<@(.*?)\\>'\n",
    "    mentions_found = re.findall(regex, text)\n",
    "    mention_lst = list(set(mentions_found) & set(user_lst))\n",
    "    for mention in mention_lst:\n",
    "        real_name = user_name_dct[mention]\n",
    "        text = text.replace('<@'+mention+'>', real_name)\n",
    "    return text\n",
    "        \n",
    "df_processed['text'] = df_processed['text'].apply(replace_mentions)\n",
    "\n",
    "#Remove extremely short texts\n",
    "def remove_short(text):\n",
    "    token_lst = text.split(' ')\n",
    "    if len(token_lst) < 3:\n",
    "        return ''\n",
    "    return text\n",
    "    \n",
    "df_processed['text'] = df_processed['text'].apply(remove_short)\n",
    "\n",
    "# Remove empty text messages\n",
    "df_processed = df_processed.loc[df_processed['text'] != ''] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17d0e4-12e8-455c-b96f-88b00a5b01d6",
   "metadata": {},
   "source": [
    "# Last step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bb8a14-6249-4307-a36e-dbe4393739d0",
   "metadata": {},
   "source": [
    "### Replace empty lists with None values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ad959ee2-aa9b-42c9-b2d4-cdd15414a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_empty(what):\n",
    "    if what == []:\n",
    "        return None\n",
    "    return what\n",
    "\n",
    "df_processed['members'] = df_processed['members'].apply(replace_empty)\n",
    "df_processed['mentions'] = df_processed['mentions'].apply(replace_empty)\n",
    "df_processed['listeners'] = df_processed['listeners'].apply(replace_empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae62d7-fec9-4fb7-9e20-c791c36e2ce9",
   "metadata": {},
   "source": [
    "### Sort by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "11da5262-9f24-4ba3-ae25-d270f417bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_processed.sort_values(by=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c7cc4-57d3-497e-80e4-563f6c62f4a1",
   "metadata": {},
   "source": [
    "### Rename column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a334b390-d31d-49a3-9484-01bb24aca1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})\n",
    "df_processed = df_processed.rename(columns={'user': 'speaker', 'explicit_addressees': 'listeners'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a7e87-c1e6-4a22-b51b-34bb8aeef53e",
   "metadata": {},
   "source": [
    "### Reindex for LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0e1a1521-a8df-4466-92b3-b2fb0b9daffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one to index value & rename index column name as 'Row ID' (to match the convention of LIWC)\n",
    "df_processed = df_processed.reset_index().drop(columns='index')\n",
    "df_processed.index = df_processed.index + 1\n",
    "df_processed.index.name = 'Row ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f95a8f-e6a2-4042-b900-10dcabf52b0c",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0b194ff8-85c4-47c5-9980-001bec8a171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.to_csv(proc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fa3f23a-9ac4-4eef-bc1e-d6ed8a902a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.to_csv(slack_text_file, columns=['text'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1be8d-9d85-4037-8f96-375c1364dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "##################################### END ######################################\n",
    "################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
